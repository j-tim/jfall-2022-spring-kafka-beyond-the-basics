# Docker compose file format 3.7 Required Docker Engine 18.06.0+
# For more information see: https://docs.docker.com/compose/compose-file/compose-versioning/
version: '3.9'

services:

  # Confluent Kafka Docker image see: https://hub.docker.com/r/confluentinc/cp-kafka/
  # Confluent Platform and Apache Kafka Compatibility:
  # https://docs.confluent.io/current/installation/versions-interoperability.html
  kafka:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION}
    container_name: kafka
    hostname: kafka
    environment:
      # KAFKA_ADVERTISED_LISTENERS: comma-separated list of listeners with their the host/ip and port.
      # This is the metadata that’s passed back to clients.
      # LISTENER_DOCKER_INTERNAL: This will make Kafka accessible from outside of the Docker network (your machine) port: 9092.
      # LISTENER_DOCKER_EXTERNAL: This will make Kafka accessible to other Docker containers by advertising it’s
      # location on the Docker network port: 29092
      KAFKA_LISTENERS: LISTENER_DOCKER_INTERNAL://:29092,LISTENER_DOCKER_EXTERNAL://:9092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka:29092,LISTENER_DOCKER_EXTERNAL://localhost:9092
      # Key/value pairs for the security protocol to use, per listener name
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      # The same ZooKeeper port is specified here as the previous container.
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      # The KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR is set to 1 for a single-node cluster. Unless you have three or more
      # nodes you do not need to change this from the default.
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3
      # Whether or not to auto create topics when data is published for the first time to a topic
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      JMX_PORT: 9999
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka -Dcom.sun.management.jmxremote.rmi.port=9999
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: 'true'
      EXTRA_ARGS: -javaagent:/usr/share/jmx-exporter/jmx_prometheus_javaagent-0.16.1.jar=1234:/usr/share/jmx-exporter/kafka_broker.yml
    ports:
      - 9092:9092
      - 9999:9999
    volumes:
      - ${PWD}/monitoring/jmx-exporter/:/usr/share/jmx-exporter
    healthcheck:
      test: echo srvr | nc kafka 9092 || exit 1
      interval: 5s
      retries: 10
    depends_on:
      zookeeper:
        condition: service_healthy

  # Confluent Zookeeper Docker image see: https://hub.docker.com/r/confluentinc/cp-zookeeper/
  zookeeper:
    container_name: zookeeper
    hostname: zookeeper
    image: confluentinc/cp-zookeeper:${CONFLUENT_PLATFORM_VERSION}
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - 2181:2181
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      interval: 10s
      retries: 20

  # Confluent Schema Registry Docker image see: https://hub.docker.com/r/confluentinc/cp-schema-registry
  # Schema Registry: http://localhost:8081
  schema-registry:
    image: confluentinc/cp-schema-registry:${CONFLUENT_PLATFORM_VERSION}
    hostname: schema-registry
    container_name: schema-registry
    environment:
      # Connects to the docker internal network port: 29092
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:29092"
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
    ports:
      - 8081:8081
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      interval: 5s
      retries: 10
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8081

  # The zipkin process services the UI, and also exposes a POST endpoint that
  # instrumentation can send trace data to. Scribe is disabled by default.
  # Zipkin: http://localhost:9411
  zipkin:
    image: openzipkin/zipkin
    container_name: zipkin
    ports:
      # Port used for the Zipkin UI and HTTP API
      - 9411:9411
    environment:
      JAVA_OPTS: "-Xms1024m -Xmx2048m -XX:+ExitOnOutOfMemoryError"

  # Login: http://localhost
  #
  # admin: username: admin@conduktor.io password: admin
  # user: username: user@conduktor.io password: user
  conduktor:
    image: conduktor/conduktor-platform:1.5.1
    hostname: conduktor
    container_name: conduktor
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --fail http://localhost/platform/api/modules/health/live"
        ]
      interval: 30s
      start_period: 120s # Leave time for the psql init scripts to run
      timeout: 5s
      retries: 3
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - 80:80
    environment:
      KAFKA_BOOTSTRAP_SERVER: 'kafka:29092'
      SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      ORGANISATION_NAME: "default"
      CDK_LISTENING_PORT: 80